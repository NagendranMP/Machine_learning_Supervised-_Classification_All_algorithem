{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02ee8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "acb29c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"Social_Network_Ads.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c070cf1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User ID            15612465\n",
       "Gender                 Male\n",
       "Age                      35\n",
       "EstimatedSalary       79000\n",
       "Purchased                 0\n",
       "Name: 337, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[337]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5218425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c04ebfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Age  EstimatedSalary  Purchased  Gender_Male\n",
       "0  15624510   19            19000          0            1\n",
       "1  15810944   35            20000          0            1\n",
       "2  15668575   26            43000          0            0\n",
       "3  15603246   27            57000          0            0\n",
       "4  15804002   19            76000          0            1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.get_dummies(df,drop_first=True).astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c66663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"Purchased\",axis=1)\n",
    "y=df[\"Purchased\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "05ab014e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c9b5664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>15809823</td>\n",
       "      <td>26</td>\n",
       "      <td>15000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>15593715</td>\n",
       "      <td>60</td>\n",
       "      <td>102000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>15619407</td>\n",
       "      <td>38</td>\n",
       "      <td>112000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>15813113</td>\n",
       "      <td>40</td>\n",
       "      <td>107000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>15800215</td>\n",
       "      <td>42</td>\n",
       "      <td>53000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>15619465</td>\n",
       "      <td>48</td>\n",
       "      <td>30000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>15779581</td>\n",
       "      <td>29</td>\n",
       "      <td>43000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>15591433</td>\n",
       "      <td>36</td>\n",
       "      <td>52000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>15776348</td>\n",
       "      <td>27</td>\n",
       "      <td>54000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>15794661</td>\n",
       "      <td>26</td>\n",
       "      <td>118000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Age  EstimatedSalary  Gender_Male\n",
       "92   15809823   26            15000            1\n",
       "223  15593715   60           102000            1\n",
       "234  15619407   38           112000            0\n",
       "232  15813113   40           107000            1\n",
       "377  15800215   42            53000            0\n",
       "..        ...  ...              ...          ...\n",
       "323  15619465   48            30000            0\n",
       "192  15779581   29            43000            1\n",
       "117  15591433   36            52000            1\n",
       "47   15776348   27            54000            0\n",
       "172  15794661   26           118000            0\n",
       "\n",
       "[280 rows x 4 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0411ebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee5712f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fa9e103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mmc=MinMaxScaler()\n",
    "m_train=mmc.fit_transform(X_train)\n",
    "m_test=mmc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "685f1ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scalar.pkl']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "joblib.dump(sc,\"scalar.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34381afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "370 fits failed out of a total of 720.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cholesky supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1168, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1178, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1227, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "                                                ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1221, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py\", line 1060, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 92, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver liblinear does not support a multinomial backend.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1218, in fit\n",
      "    multi_class = _check_multi_class(self.multi_class, solver, len(self.classes_))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 92, in _check_multi_class\n",
      "    raise ValueError(\"Solver %s does not support a multinomial backend.\" % solver)\n",
      "ValueError: Solver newton-cholesky does not support a multinomial backend.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan 0.83214286        nan        nan        nan 0.825\n",
      " 0.825      0.82857143 0.825      0.825      0.825      0.825\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.825             nan 0.825      0.825      0.825      0.825\n",
      "        nan 0.83214286        nan        nan        nan 0.825\n",
      " 0.825      0.82857143 0.825      0.825      0.825      0.825\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.825             nan 0.825      0.825      0.825      0.825\n",
      "        nan        nan        nan        nan        nan 0.825\n",
      " 0.825             nan 0.825             nan 0.825      0.825\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.825             nan 0.825             nan 0.825      0.825\n",
      "        nan 0.81785714        nan        nan        nan 0.81428571\n",
      " 0.82142857 0.81785714 0.82142857 0.82142857 0.82142857 0.82142857\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.81785714        nan 0.81785714 0.81785714 0.81785714 0.81785714\n",
      "        nan 0.81785714        nan        nan        nan 0.81428571\n",
      " 0.82142857 0.81785714 0.82142857 0.82142857 0.82142857 0.82142857\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.81785714        nan 0.81785714 0.81785714 0.81785714 0.81785714\n",
      "        nan        nan        nan        nan        nan 0.81428571\n",
      " 0.82142857        nan 0.82142857        nan 0.82142857 0.82142857\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.81785714        nan 0.81785714        nan 0.81785714 0.81785714]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;, &#x27;multinomial&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={&#x27;class_weight&#x27;: [None, &#x27;balanced&#x27;],\n",
       "                         &#x27;multi_class&#x27;: [&#x27;auto&#x27;, &#x27;ovr&#x27;, &#x27;multinomial&#x27;],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, None],\n",
       "                         &#x27;solver&#x27;: [&#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;newton-cg&#x27;,\n",
       "                                    &#x27;newton-cholesky&#x27;, &#x27;sag&#x27;, &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'class_weight': [None, 'balanced'],\n",
       "                         'multi_class': ['auto', 'ovr', 'multinomial'],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', None],\n",
       "                         'solver': ['lbfgs', 'liblinear', 'newton-cg',\n",
       "                                    'newton-cholesky', 'sag', 'saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "paraLR={\"penalty\":[\"l1\", \"l2\", \"elasticnet\", None],\n",
    "       \"class_weight\":[None,\"balanced\"],\n",
    "       \"solver\":[\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\"],\n",
    "       \"multi_class\":[\"auto\", \"ovr\", \"multinomial\"]}\n",
    "gridLR=GridSearchCV(LogisticRegression(),paraLR,refit=True,verbose=3,n_jobs=-1)\n",
    "gridLR.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89a3f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=gridLR.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee36293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "re=gridLR.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52703107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_multi_class</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'class_weight': None, 'multi_class': 'auto', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'class_weight': None, 'multi_class': 'auto', ...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.832143</td>\n",
       "      <td>0.087190</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'class_weight': None, 'multi_class': 'auto', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'class_weight': None, 'multi_class': 'auto', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>None</td>\n",
       "      <td>auto</td>\n",
       "      <td>l1</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'class_weight': None, 'multi_class': 'auto', ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'class_weight': 'balanced', 'multi_class': 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.008519</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>balanced</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'class_weight': 'balanced', 'multi_class': 'm...</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.056919</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>balanced</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>newton-cholesky</td>\n",
       "      <td>{'class_weight': 'balanced', 'multi_class': 'm...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>balanced</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>sag</td>\n",
       "      <td>{'class_weight': 'balanced', 'multi_class': 'm...</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.056919</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.005853</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>balanced</td>\n",
       "      <td>multinomial</td>\n",
       "      <td>None</td>\n",
       "      <td>saga</td>\n",
       "      <td>{'class_weight': 'balanced', 'multi_class': 'm...</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.056919</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.001458      0.000714         0.000000        0.000000   \n",
       "1         0.003021      0.000458         0.001876        0.000696   \n",
       "2         0.001193      0.000800         0.000000        0.000000   \n",
       "3         0.000373      0.000594         0.000000        0.000000   \n",
       "4         0.000804      0.000492         0.000000        0.000000   \n",
       "..             ...           ...              ...             ...   \n",
       "139       0.001102      0.000128         0.000000        0.000000   \n",
       "140       0.008519      0.001495         0.000569        0.000468   \n",
       "141       0.000816      0.000776         0.000000        0.000000   \n",
       "142       0.007271      0.004246         0.000969        0.000586   \n",
       "143       0.005853      0.003342         0.000968        0.000078   \n",
       "\n",
       "    param_class_weight param_multi_class param_penalty     param_solver  \\\n",
       "0                 None              auto            l1            lbfgs   \n",
       "1                 None              auto            l1        liblinear   \n",
       "2                 None              auto            l1        newton-cg   \n",
       "3                 None              auto            l1  newton-cholesky   \n",
       "4                 None              auto            l1              sag   \n",
       "..                 ...               ...           ...              ...   \n",
       "139           balanced       multinomial          None        liblinear   \n",
       "140           balanced       multinomial          None        newton-cg   \n",
       "141           balanced       multinomial          None  newton-cholesky   \n",
       "142           balanced       multinomial          None              sag   \n",
       "143           balanced       multinomial          None             saga   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'class_weight': None, 'multi_class': 'auto', ...                NaN   \n",
       "1    {'class_weight': None, 'multi_class': 'auto', ...           0.857143   \n",
       "2    {'class_weight': None, 'multi_class': 'auto', ...                NaN   \n",
       "3    {'class_weight': None, 'multi_class': 'auto', ...                NaN   \n",
       "4    {'class_weight': None, 'multi_class': 'auto', ...                NaN   \n",
       "..                                                 ...                ...   \n",
       "139  {'class_weight': 'balanced', 'multi_class': 'm...                NaN   \n",
       "140  {'class_weight': 'balanced', 'multi_class': 'm...           0.821429   \n",
       "141  {'class_weight': 'balanced', 'multi_class': 'm...                NaN   \n",
       "142  {'class_weight': 'balanced', 'multi_class': 'm...           0.821429   \n",
       "143  {'class_weight': 'balanced', 'multi_class': 'm...           0.821429   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0                  NaN                NaN                NaN   \n",
       "1             0.803571           0.678571           0.928571   \n",
       "2                  NaN                NaN                NaN   \n",
       "3                  NaN                NaN                NaN   \n",
       "4                  NaN                NaN                NaN   \n",
       "..                 ...                ...                ...   \n",
       "139                NaN                NaN                NaN   \n",
       "140           0.803571           0.732143           0.821429   \n",
       "141                NaN                NaN                NaN   \n",
       "142           0.803571           0.732143           0.821429   \n",
       "143           0.803571           0.732143           0.821429   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0                  NaN              NaN             NaN               71  \n",
       "1             0.892857         0.832143        0.087190                1  \n",
       "2                  NaN              NaN             NaN               71  \n",
       "3                  NaN              NaN             NaN               71  \n",
       "4                  NaN              NaN             NaN               71  \n",
       "..                 ...              ...             ...              ...  \n",
       "139                NaN              NaN             NaN               71  \n",
       "140           0.910714         0.817857        0.056919               50  \n",
       "141                NaN              NaN             NaN               71  \n",
       "142           0.910714         0.817857        0.056919               50  \n",
       "143           0.910714         0.817857        0.056919               50  \n",
       "\n",
       "[144 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame.from_dict(re)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66f98a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75,  4],\n",
       "       [10, 31]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "classi=confusion_matrix(y_test,y_pred)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbd426f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.88      0.95      0.91        79\\n           1       0.89      0.76      0.82        41\\n\\n    accuracy                           0.88       120\\n   macro avg       0.88      0.85      0.87       120\\nweighted avg       0.88      0.88      0.88       120\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report=classification_report(y_test,y_pred)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b25c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [1.0, 10, 100, 1000, 2000, 3000],\n",
       "                         &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={&#x27;C&#x27;: [1.0, 10, 100, 1000, 2000, 3000],\n",
       "                         &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=SVC(), n_jobs=-1,\n",
       "             param_grid={'C': [1.0, 10, 100, 1000, 2000, 3000],\n",
       "                         'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "paraSVC={\"kernel\":[\"linear\",\"poly\", \"rbf\", \"sigmoid\"],\n",
    "        \"gamma\":[\"scale\", \"auto\"],\n",
    "        \"C\":[1.0,10,100,1000,2000,3000]}\n",
    "gridSVC=GridSearchCV(SVC(),paraSVC,refit=True,verbose=3,n_jobs=-1)\n",
    "gridSVC.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbaf9552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.085267</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005601</td>\n",
       "      <td>0.003558</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.002394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.072668</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003059</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003603</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>1.0</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.066815</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>1.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'auto', 'kernel': 'linear'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.085267</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.003462</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>1.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'auto', 'kernel': 'poly'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.072668</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003822</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1.0, 'gamma': 'auto', 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.072843</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.086455</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004409</td>\n",
       "      <td>0.001471</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.001932</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.048708</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001812</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.041342</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001695</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>10</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.710714</td>\n",
       "      <td>0.073540</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'gamma': 'auto', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.086455</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 10, 'gamma': 'auto', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.048708</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.041342</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005567</td>\n",
       "      <td>0.003232</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 10, 'gamma': 'auto', 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.053690</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.025024</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>100</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 100, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.019873</td>\n",
       "      <td>0.004451</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 100, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.048708</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.005096</td>\n",
       "      <td>0.004995</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>100</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.005840</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>100</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 100, 'gamma': 'scale', 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.059761</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.017491</td>\n",
       "      <td>0.001488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 100, 'gamma': 'auto', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.021242</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 100, 'gamma': 'auto', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.048708</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.006164</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.013363</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.004788</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>100</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.052489</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.202855</td>\n",
       "      <td>0.116708</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>1000</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1000, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.159739</td>\n",
       "      <td>0.060060</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>1000</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1000, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.008922</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.003221</td>\n",
       "      <td>1000</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.032733</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.005514</td>\n",
       "      <td>0.005884</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>1000</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1000, 'gamma': 'scale', 'kernel': 'sigmo...</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.721429</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.204245</td>\n",
       "      <td>0.111707</td>\n",
       "      <td>0.003619</td>\n",
       "      <td>0.003683</td>\n",
       "      <td>1000</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1000, 'gamma': 'auto', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.154274</td>\n",
       "      <td>0.060610</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>1000</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 1000, 'gamma': 'auto', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.011742</td>\n",
       "      <td>0.004322</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>1000</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.034626</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001666</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>1000</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 1000, 'gamma': 'auto', 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.717857</td>\n",
       "      <td>0.052245</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.532877</td>\n",
       "      <td>0.431447</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>2000</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 2000, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.373429</td>\n",
       "      <td>0.233028</td>\n",
       "      <td>0.001711</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>2000</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 2000, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>2000</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 2000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.024223</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.003619</td>\n",
       "      <td>0.003277</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>2000</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 2000, 'gamma': 'scale', 'kernel': 'sigmo...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.728571</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.570591</td>\n",
       "      <td>0.519565</td>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>2000</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 2000, 'gamma': 'auto', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.358150</td>\n",
       "      <td>0.216093</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>2000</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 2000, 'gamma': 'auto', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.013685</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>2000</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 2000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.003848</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>2000</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 2000, 'gamma': 'auto', 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.721429</td>\n",
       "      <td>0.053690</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.670541</td>\n",
       "      <td>0.311883</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>3000</td>\n",
       "      <td>scale</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 3000, 'gamma': 'scale', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.470051</td>\n",
       "      <td>0.244523</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>3000</td>\n",
       "      <td>scale</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 3000, 'gamma': 'scale', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>3000</td>\n",
       "      <td>scale</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 3000, 'gamma': 'scale', 'kernel': 'rbf'}</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.001504</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>3000</td>\n",
       "      <td>scale</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 3000, 'gamma': 'scale', 'kernel': 'sigmo...</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.053452</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.704204</td>\n",
       "      <td>0.355807</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>3000</td>\n",
       "      <td>auto</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 3000, 'gamma': 'auto', 'kernel': 'linear'}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.327373</td>\n",
       "      <td>0.117917</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>3000</td>\n",
       "      <td>auto</td>\n",
       "      <td>poly</td>\n",
       "      <td>{'C': 3000, 'gamma': 'auto', 'kernel': 'poly'}</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.039123</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.009041</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>3000</td>\n",
       "      <td>auto</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 3000, 'gamma': 'auto', 'kernel': 'rbf'}</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.002115</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>3000</td>\n",
       "      <td>auto</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>{'C': 3000, 'gamma': 'auto', 'kernel': 'sigmoid'}</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.721429</td>\n",
       "      <td>0.053690</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.001680      0.001095         0.001202        0.002404     1.0   \n",
       "1        0.005601      0.003558         0.002220        0.002394     1.0   \n",
       "2        0.003059      0.000632         0.002729        0.001468     1.0   \n",
       "3        0.003603      0.001097         0.002076        0.000640     1.0   \n",
       "4        0.002782      0.000716         0.001314        0.000964     1.0   \n",
       "5        0.003462      0.000559         0.001321        0.000694     1.0   \n",
       "6        0.003822      0.000455         0.001319        0.000885     1.0   \n",
       "7        0.002849      0.001109         0.002507        0.001747     1.0   \n",
       "8        0.004778      0.001255         0.000435        0.000534      10   \n",
       "9        0.004409      0.001471         0.001578        0.001932      10   \n",
       "10       0.001812      0.001849         0.001573        0.002194      10   \n",
       "11       0.001625      0.001695         0.001858        0.002286      10   \n",
       "12       0.004380      0.002492         0.000861        0.001722      10   \n",
       "13       0.004873      0.002445         0.002142        0.003317      10   \n",
       "14       0.002459      0.002052         0.002543        0.003151      10   \n",
       "15       0.005567      0.003232         0.000357        0.000450      10   \n",
       "16       0.025024      0.005865         0.000200        0.000399     100   \n",
       "17       0.019873      0.004451         0.000000        0.000000     100   \n",
       "18       0.005096      0.004995         0.001006        0.002012     100   \n",
       "19       0.000200      0.000399         0.005840        0.006001     100   \n",
       "20       0.017491      0.001488         0.000000        0.000000     100   \n",
       "21       0.021242      0.015308         0.001043        0.002087     100   \n",
       "22       0.003325      0.006164         0.003745        0.005283     100   \n",
       "23       0.004788      0.007138         0.000474        0.000592     100   \n",
       "24       0.202855      0.116708         0.000320        0.000639    1000   \n",
       "25       0.159739      0.060060         0.000699        0.000753    1000   \n",
       "26       0.008922      0.004756         0.001610        0.003221    1000   \n",
       "27       0.005514      0.005884         0.000879        0.001518    1000   \n",
       "28       0.204245      0.111707         0.003619        0.003683    1000   \n",
       "29       0.154274      0.060610         0.001804        0.003133    1000   \n",
       "30       0.011742      0.004322         0.001730        0.001692    1000   \n",
       "31       0.001666      0.001119         0.001105        0.001754    1000   \n",
       "32       0.532877      0.431447         0.000995        0.000889    2000   \n",
       "33       0.373429      0.233028         0.001711        0.002101    2000   \n",
       "34       0.012819      0.005309         0.001808        0.002730    2000   \n",
       "35       0.003619      0.003277         0.001713        0.002539    2000   \n",
       "36       0.570591      0.519565         0.001504        0.003007    2000   \n",
       "37       0.358150      0.216093         0.001066        0.001307    2000   \n",
       "38       0.013685      0.003686         0.001802        0.002645    2000   \n",
       "39       0.000706      0.000754         0.003848        0.003652    2000   \n",
       "40       0.670541      0.311883         0.000905        0.001810    3000   \n",
       "41       0.470051      0.244523         0.000409        0.000501    3000   \n",
       "42       0.009663      0.004122         0.002114        0.003125    3000   \n",
       "43       0.001504      0.001490         0.000433        0.000865    3000   \n",
       "44       0.704204      0.355807         0.000460        0.000572    3000   \n",
       "45       0.327373      0.117917         0.001182        0.000816    3000   \n",
       "46       0.009041      0.001926         0.000924        0.000816    3000   \n",
       "47       0.002115      0.001542         0.000836        0.001025    3000   \n",
       "\n",
       "   param_gamma param_kernel  \\\n",
       "0        scale       linear   \n",
       "1        scale         poly   \n",
       "2        scale          rbf   \n",
       "3        scale      sigmoid   \n",
       "4         auto       linear   \n",
       "5         auto         poly   \n",
       "6         auto          rbf   \n",
       "7         auto      sigmoid   \n",
       "8        scale       linear   \n",
       "9        scale         poly   \n",
       "10       scale          rbf   \n",
       "11       scale      sigmoid   \n",
       "12        auto       linear   \n",
       "13        auto         poly   \n",
       "14        auto          rbf   \n",
       "15        auto      sigmoid   \n",
       "16       scale       linear   \n",
       "17       scale         poly   \n",
       "18       scale          rbf   \n",
       "19       scale      sigmoid   \n",
       "20        auto       linear   \n",
       "21        auto         poly   \n",
       "22        auto          rbf   \n",
       "23        auto      sigmoid   \n",
       "24       scale       linear   \n",
       "25       scale         poly   \n",
       "26       scale          rbf   \n",
       "27       scale      sigmoid   \n",
       "28        auto       linear   \n",
       "29        auto         poly   \n",
       "30        auto          rbf   \n",
       "31        auto      sigmoid   \n",
       "32       scale       linear   \n",
       "33       scale         poly   \n",
       "34       scale          rbf   \n",
       "35       scale      sigmoid   \n",
       "36        auto       linear   \n",
       "37        auto         poly   \n",
       "38        auto          rbf   \n",
       "39        auto      sigmoid   \n",
       "40       scale       linear   \n",
       "41       scale         poly   \n",
       "42       scale          rbf   \n",
       "43       scale      sigmoid   \n",
       "44        auto       linear   \n",
       "45        auto         poly   \n",
       "46        auto          rbf   \n",
       "47        auto      sigmoid   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0    {'C': 1.0, 'gamma': 'scale', 'kernel': 'linear'}           0.839286   \n",
       "1      {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}           0.857143   \n",
       "2       {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}           0.875000   \n",
       "3   {'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid'}           0.821429   \n",
       "4     {'C': 1.0, 'gamma': 'auto', 'kernel': 'linear'}           0.839286   \n",
       "5       {'C': 1.0, 'gamma': 'auto', 'kernel': 'poly'}           0.857143   \n",
       "6        {'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf'}           0.875000   \n",
       "7    {'C': 1.0, 'gamma': 'auto', 'kernel': 'sigmoid'}           0.803571   \n",
       "8     {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}           0.857143   \n",
       "9       {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}           0.839286   \n",
       "10       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}           0.892857   \n",
       "11   {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}           0.785714   \n",
       "12     {'C': 10, 'gamma': 'auto', 'kernel': 'linear'}           0.857143   \n",
       "13       {'C': 10, 'gamma': 'auto', 'kernel': 'poly'}           0.839286   \n",
       "14        {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}           0.892857   \n",
       "15    {'C': 10, 'gamma': 'auto', 'kernel': 'sigmoid'}           0.785714   \n",
       "16   {'C': 100, 'gamma': 'scale', 'kernel': 'linear'}           0.857143   \n",
       "17     {'C': 100, 'gamma': 'scale', 'kernel': 'poly'}           0.839286   \n",
       "18      {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}           0.875000   \n",
       "19  {'C': 100, 'gamma': 'scale', 'kernel': 'sigmoid'}           0.803571   \n",
       "20    {'C': 100, 'gamma': 'auto', 'kernel': 'linear'}           0.857143   \n",
       "21      {'C': 100, 'gamma': 'auto', 'kernel': 'poly'}           0.839286   \n",
       "22       {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}           0.875000   \n",
       "23   {'C': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}           0.767857   \n",
       "24  {'C': 1000, 'gamma': 'scale', 'kernel': 'linear'}           0.857143   \n",
       "25    {'C': 1000, 'gamma': 'scale', 'kernel': 'poly'}           0.839286   \n",
       "26     {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}           0.785714   \n",
       "27  {'C': 1000, 'gamma': 'scale', 'kernel': 'sigmo...           0.732143   \n",
       "28   {'C': 1000, 'gamma': 'auto', 'kernel': 'linear'}           0.857143   \n",
       "29     {'C': 1000, 'gamma': 'auto', 'kernel': 'poly'}           0.839286   \n",
       "30      {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}           0.785714   \n",
       "31  {'C': 1000, 'gamma': 'auto', 'kernel': 'sigmoid'}           0.732143   \n",
       "32  {'C': 2000, 'gamma': 'scale', 'kernel': 'linear'}           0.857143   \n",
       "33    {'C': 2000, 'gamma': 'scale', 'kernel': 'poly'}           0.839286   \n",
       "34     {'C': 2000, 'gamma': 'scale', 'kernel': 'rbf'}           0.803571   \n",
       "35  {'C': 2000, 'gamma': 'scale', 'kernel': 'sigmo...           0.750000   \n",
       "36   {'C': 2000, 'gamma': 'auto', 'kernel': 'linear'}           0.857143   \n",
       "37     {'C': 2000, 'gamma': 'auto', 'kernel': 'poly'}           0.839286   \n",
       "38      {'C': 2000, 'gamma': 'auto', 'kernel': 'rbf'}           0.803571   \n",
       "39  {'C': 2000, 'gamma': 'auto', 'kernel': 'sigmoid'}           0.750000   \n",
       "40  {'C': 3000, 'gamma': 'scale', 'kernel': 'linear'}           0.857143   \n",
       "41    {'C': 3000, 'gamma': 'scale', 'kernel': 'poly'}           0.839286   \n",
       "42     {'C': 3000, 'gamma': 'scale', 'kernel': 'rbf'}           0.785714   \n",
       "43  {'C': 3000, 'gamma': 'scale', 'kernel': 'sigmo...           0.785714   \n",
       "44   {'C': 3000, 'gamma': 'auto', 'kernel': 'linear'}           0.857143   \n",
       "45     {'C': 3000, 'gamma': 'auto', 'kernel': 'poly'}           0.839286   \n",
       "46      {'C': 3000, 'gamma': 'auto', 'kernel': 'rbf'}           0.785714   \n",
       "47  {'C': 3000, 'gamma': 'auto', 'kernel': 'sigmoid'}           0.750000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.785714           0.678571           0.928571   \n",
       "1            0.785714           0.696429           0.839286   \n",
       "2            0.875000           0.839286           0.928571   \n",
       "3            0.750000           0.678571           0.875000   \n",
       "4            0.785714           0.678571           0.928571   \n",
       "5            0.785714           0.696429           0.839286   \n",
       "6            0.875000           0.839286           0.928571   \n",
       "7            0.732143           0.660714           0.875000   \n",
       "8            0.750000           0.678571           0.910714   \n",
       "9            0.803571           0.750000           0.785714   \n",
       "10           0.857143           0.821429           0.875000   \n",
       "11           0.714286           0.571429           0.750000   \n",
       "12           0.750000           0.678571           0.910714   \n",
       "13           0.803571           0.750000           0.785714   \n",
       "14           0.857143           0.821429           0.875000   \n",
       "15           0.660714           0.642857           0.750000   \n",
       "16           0.750000           0.678571           0.928571   \n",
       "17           0.785714           0.732143           0.821429   \n",
       "18           0.857143           0.857143           0.875000   \n",
       "19           0.732143           0.625000           0.732143   \n",
       "20           0.750000           0.678571           0.928571   \n",
       "21           0.785714           0.732143           0.821429   \n",
       "22           0.857143           0.857143           0.875000   \n",
       "23           0.732143           0.625000           0.732143   \n",
       "24           0.750000           0.678571           0.928571   \n",
       "25           0.785714           0.767857           0.839286   \n",
       "26           0.857143           0.785714           0.803571   \n",
       "27           0.714286           0.642857           0.767857   \n",
       "28           0.750000           0.678571           0.928571   \n",
       "29           0.785714           0.767857           0.839286   \n",
       "30           0.839286           0.785714           0.803571   \n",
       "31           0.732143           0.625000           0.785714   \n",
       "32           0.750000           0.678571           0.928571   \n",
       "33           0.785714           0.767857           0.839286   \n",
       "34           0.821429           0.785714           0.803571   \n",
       "35           0.750000           0.642857           0.750000   \n",
       "36           0.750000           0.678571           0.928571   \n",
       "37           0.785714           0.767857           0.839286   \n",
       "38           0.821429           0.803571           0.803571   \n",
       "39           0.732143           0.625000           0.785714   \n",
       "40           0.750000           0.678571           0.928571   \n",
       "41           0.785714           0.767857           0.839286   \n",
       "42           0.803571           0.785714           0.803571   \n",
       "43           0.714286           0.642857           0.785714   \n",
       "44           0.750000           0.678571           0.928571   \n",
       "45           0.785714           0.767857           0.839286   \n",
       "46           0.803571           0.785714           0.785714   \n",
       "47           0.732143           0.625000           0.785714   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.875000         0.821429        0.085267                7  \n",
       "1            0.910714         0.817857        0.072668               15  \n",
       "2            0.946429         0.892857        0.039123                1  \n",
       "3            0.803571         0.785714        0.066815               37  \n",
       "4            0.875000         0.821429        0.085267                7  \n",
       "5            0.910714         0.817857        0.072668               15  \n",
       "6            0.946429         0.892857        0.039123                1  \n",
       "7            0.803571         0.775000        0.072843               38  \n",
       "8            0.875000         0.814286        0.086455               28  \n",
       "9            0.892857         0.814286        0.048708               28  \n",
       "10           0.946429         0.878571        0.041342                3  \n",
       "11           0.732143         0.710714        0.073540               47  \n",
       "12           0.875000         0.814286        0.086455               28  \n",
       "13           0.892857         0.814286        0.048708               28  \n",
       "14           0.946429         0.878571        0.041342                3  \n",
       "15           0.696429         0.707143        0.053690               48  \n",
       "16           0.875000         0.817857        0.090633               15  \n",
       "17           0.875000         0.810714        0.048708               33  \n",
       "18           0.892857         0.871429        0.013363                5  \n",
       "19           0.767857         0.732143        0.059761               40  \n",
       "20           0.875000         0.817857        0.090633               15  \n",
       "21           0.875000         0.810714        0.048708               33  \n",
       "22           0.892857         0.871429        0.013363                5  \n",
       "23           0.767857         0.725000        0.052489               42  \n",
       "24           0.875000         0.817857        0.090633               15  \n",
       "25           0.875000         0.821429        0.039123                7  \n",
       "26           0.857143         0.817857        0.032733               27  \n",
       "27           0.750000         0.721429        0.043154               43  \n",
       "28           0.875000         0.817857        0.090633               15  \n",
       "29           0.875000         0.821429        0.039123                7  \n",
       "30           0.875000         0.817857        0.034626               15  \n",
       "31           0.714286         0.717857        0.052245               46  \n",
       "32           0.875000         0.817857        0.090633               15  \n",
       "33           0.875000         0.821429        0.039123                7  \n",
       "34           0.857143         0.814286        0.024223               28  \n",
       "35           0.750000         0.728571        0.042857               41  \n",
       "36           0.875000         0.817857        0.090633               15  \n",
       "37           0.875000         0.821429        0.039123                7  \n",
       "38           0.857143         0.817857        0.020825               15  \n",
       "39           0.714286         0.721429        0.053690               43  \n",
       "40           0.875000         0.817857        0.090633               15  \n",
       "41           0.875000         0.821429        0.039123                7  \n",
       "42           0.839286         0.803571        0.019562               35  \n",
       "43           0.750000         0.735714        0.053452               39  \n",
       "44           0.875000         0.817857        0.090633               15  \n",
       "45           0.875000         0.821429        0.039123                7  \n",
       "46           0.839286         0.800000        0.020825               36  \n",
       "47           0.714286         0.721429        0.053690               43  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1=gridSVC.predict(X_test)\n",
    "re1=gridSVC.cv_results_\n",
    "data1=pd.DataFrame.from_dict(re1)\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48525269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73,  6],\n",
       "       [ 5, 36]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi=confusion_matrix(y_test,y_pred1)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eac47e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.94      0.92      0.93        79\\n           1       0.86      0.88      0.87        41\\n\\n    accuracy                           0.91       120\\n   macro avg       0.90      0.90      0.90       120\\nweighted avg       0.91      0.91      0.91       120\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(y_test,y_pred1)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0539b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'splitter': ['best', 'random']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "paraDT={\"criterion\":[\"gini\", \"entropy\", \"log_loss\"],\n",
    "       \"splitter\":[\"best\", \"random\"],\n",
    "        \"max_features\":[\"sqrt\",\"log2\"]}\n",
    "gridDT=GridSearchCV(DecisionTreeClassifier(),paraDT,refit=True,verbose=3,n_jobs=-1)\n",
    "gridDT.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed5df1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.000843</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.054632</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.064484</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002271</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.832143</td>\n",
       "      <td>0.048708</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.810714</td>\n",
       "      <td>0.018211</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003623</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.025254</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>0.041342</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003113</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.065465</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.001055</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.001729</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.056919</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>best</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.038465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.001867</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.001068</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>random</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.817857</td>\n",
       "      <td>0.034626</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.002533      0.000843         0.000880        0.000826   \n",
       "1        0.002272      0.001328         0.001899        0.001255   \n",
       "2        0.002271      0.000747         0.000475        0.000950   \n",
       "3        0.001907      0.001980         0.001799        0.001865   \n",
       "4        0.003623      0.001518         0.001415        0.000266   \n",
       "5        0.002399      0.000619         0.001438        0.000544   \n",
       "6        0.003113      0.001300         0.001284        0.000844   \n",
       "7        0.002225      0.000228         0.001055        0.000668   \n",
       "8        0.002189      0.001729         0.001439        0.001537   \n",
       "9        0.002038      0.001710         0.002237        0.001025   \n",
       "10       0.001505      0.000444         0.001705        0.000397   \n",
       "11       0.001867      0.000256         0.001068        0.000143   \n",
       "\n",
       "   param_criterion param_max_features param_splitter  \\\n",
       "0             gini               sqrt           best   \n",
       "1             gini               sqrt         random   \n",
       "2             gini               log2           best   \n",
       "3             gini               log2         random   \n",
       "4          entropy               sqrt           best   \n",
       "5          entropy               sqrt         random   \n",
       "6          entropy               log2           best   \n",
       "7          entropy               log2         random   \n",
       "8         log_loss               sqrt           best   \n",
       "9         log_loss               sqrt         random   \n",
       "10        log_loss               log2           best   \n",
       "11        log_loss               log2         random   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.857143   \n",
       "1   {'criterion': 'gini', 'max_features': 'sqrt', ...           0.839286   \n",
       "2   {'criterion': 'gini', 'max_features': 'log2', ...           0.803571   \n",
       "3   {'criterion': 'gini', 'max_features': 'log2', ...           0.839286   \n",
       "4   {'criterion': 'entropy', 'max_features': 'sqrt...           0.821429   \n",
       "5   {'criterion': 'entropy', 'max_features': 'sqrt...           0.892857   \n",
       "6   {'criterion': 'entropy', 'max_features': 'log2...           0.803571   \n",
       "7   {'criterion': 'entropy', 'max_features': 'log2...           0.839286   \n",
       "8   {'criterion': 'log_loss', 'max_features': 'sqr...           0.839286   \n",
       "9   {'criterion': 'log_loss', 'max_features': 'sqr...           0.839286   \n",
       "10  {'criterion': 'log_loss', 'max_features': 'log...           0.875000   \n",
       "11  {'criterion': 'log_loss', 'max_features': 'log...           0.875000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.803571           0.857143           0.767857   \n",
       "1            0.821429           0.857143           0.767857   \n",
       "2            0.803571           0.803571           0.821429   \n",
       "3            0.803571           0.785714           0.821429   \n",
       "4            0.857143           0.803571           0.839286   \n",
       "5            0.785714           0.821429           0.803571   \n",
       "6            0.785714           0.803571           0.910714   \n",
       "7            0.839286           0.785714           0.839286   \n",
       "8            0.803571           0.767857           0.821429   \n",
       "9            0.857143           0.839286           0.750000   \n",
       "10           0.875000           0.803571           0.803571   \n",
       "11           0.785714           0.785714           0.803571   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.928571         0.842857        0.054632                4  \n",
       "1            0.964286         0.850000        0.064484                2  \n",
       "2            0.928571         0.832143        0.048708                8  \n",
       "3            0.803571         0.810714        0.018211               12  \n",
       "4            0.875000         0.839286        0.025254                6  \n",
       "5            0.875000         0.835714        0.041342                7  \n",
       "6            0.946429         0.850000        0.065465                2  \n",
       "7            0.839286         0.828571        0.021429                9  \n",
       "8            0.875000         0.821429        0.035714               10  \n",
       "9            0.928571         0.842857        0.056919                4  \n",
       "10           0.892857         0.850000        0.038465                1  \n",
       "11           0.839286         0.817857        0.034626               11  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2=gridDT.predict(X_test)\n",
    "re2=gridDT.cv_results_\n",
    "data2=pd.DataFrame.from_dict(re2)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "886899f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73,  6],\n",
       "       [ 7, 34]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi=confusion_matrix(y_test,y_pred2)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fe3610c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.91      0.92      0.92        79\\n           1       0.85      0.83      0.84        41\\n\\n    accuracy                           0.89       120\\n   macro avg       0.88      0.88      0.88       120\\nweighted avg       0.89      0.89      0.89       120\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(y_test,y_pred2)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fd2b817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [100]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;, None],\n",
       "                         &#x27;n_estimators&#x27;: [100]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2', None],\n",
       "                         'n_estimators': [100]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "paraRF={\"criterion\":[\"gini\", \"entropy\", \"log_loss\"],\n",
    "       \"max_features\":[\"sqrt\", \"log2\", None],\n",
    "       \"n_estimators\":[100]}\n",
    "gridRF=GridSearchCV(RandomForestClassifier(),paraRF,refit=True,verbose=3,n_jobs=-1)\n",
    "gridRF.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a2ceb0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.303088</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.022296</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>gini</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'sqrt', ...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.037457</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.304224</td>\n",
       "      <td>0.008072</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>gini</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': 'log2', ...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.038132</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.335450</td>\n",
       "      <td>0.009545</td>\n",
       "      <td>0.021603</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>gini</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'gini', 'max_features': None, 'n...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.051010</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.310532</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>0.023267</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>entropy</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'sqrt...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.038465</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309692</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.019820</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>entropy</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 'log2...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.339926</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.021067</td>\n",
       "      <td>0.001975</td>\n",
       "      <td>entropy</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': None,...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.039770</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.321093</td>\n",
       "      <td>0.026715</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'sqr...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.896429</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.328179</td>\n",
       "      <td>0.031096</td>\n",
       "      <td>0.023041</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>log2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': 'log...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.040721</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.277956</td>\n",
       "      <td>0.020551</td>\n",
       "      <td>0.016113</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>log_loss</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'log_loss', 'max_features': None...</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.889286</td>\n",
       "      <td>0.047110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.303088      0.008211         0.022296        0.002009   \n",
       "1       0.304224      0.008072         0.021400        0.002118   \n",
       "2       0.335450      0.009545         0.021603        0.002271   \n",
       "3       0.310532      0.007397         0.023267        0.003147   \n",
       "4       0.309692      0.008545         0.019820        0.000754   \n",
       "5       0.339926      0.005251         0.021067        0.001975   \n",
       "6       0.321093      0.026715         0.019971        0.001667   \n",
       "7       0.328179      0.031096         0.023041        0.003505   \n",
       "8       0.277956      0.020551         0.016113        0.002301   \n",
       "\n",
       "  param_criterion param_max_features param_n_estimators  \\\n",
       "0            gini               sqrt                100   \n",
       "1            gini               log2                100   \n",
       "2            gini               None                100   \n",
       "3         entropy               sqrt                100   \n",
       "4         entropy               log2                100   \n",
       "5         entropy               None                100   \n",
       "6        log_loss               sqrt                100   \n",
       "7        log_loss               log2                100   \n",
       "8        log_loss               None                100   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'criterion': 'gini', 'max_features': 'sqrt', ...           0.875000   \n",
       "1  {'criterion': 'gini', 'max_features': 'log2', ...           0.875000   \n",
       "2  {'criterion': 'gini', 'max_features': None, 'n...           0.839286   \n",
       "3  {'criterion': 'entropy', 'max_features': 'sqrt...           0.875000   \n",
       "4  {'criterion': 'entropy', 'max_features': 'log2...           0.875000   \n",
       "5  {'criterion': 'entropy', 'max_features': None,...           0.839286   \n",
       "6  {'criterion': 'log_loss', 'max_features': 'sqr...           0.875000   \n",
       "7  {'criterion': 'log_loss', 'max_features': 'log...           0.875000   \n",
       "8  {'criterion': 'log_loss', 'max_features': None...           0.892857   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.875000           0.857143           0.892857           0.964286   \n",
       "1           0.857143           0.875000           0.910714           0.964286   \n",
       "2           0.839286           0.839286           0.910714           0.964286   \n",
       "3           0.857143           0.839286           0.910714           0.946429   \n",
       "4           0.857143           0.857143           0.928571           0.964286   \n",
       "5           0.857143           0.839286           0.875000           0.946429   \n",
       "6           0.857143           0.857143           0.928571           0.964286   \n",
       "7           0.857143           0.857143           0.910714           0.964286   \n",
       "8           0.839286           0.839286           0.910714           0.964286   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.892857        0.037457                4  \n",
       "1         0.896429        0.038132                3  \n",
       "2         0.878571        0.051010                8  \n",
       "3         0.885714        0.038465                7  \n",
       "4         0.896429        0.042857                1  \n",
       "5         0.871429        0.039770                9  \n",
       "6         0.896429        0.042857                1  \n",
       "7         0.892857        0.040721                4  \n",
       "8         0.889286        0.047110                6  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred3=gridRF.predict(X_test)\n",
    "re3=gridRF.cv_results_\n",
    "data3=pd.DataFrame.from_dict(re3)\n",
    "data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c543cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[72,  7],\n",
       "       [ 3, 38]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi=confusion_matrix(y_test,y_pred3)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "826029b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.96      0.91      0.94        79\\n           1       0.84      0.93      0.88        41\\n\\n    accuracy                           0.92       120\\n   macro avg       0.90      0.92      0.91       120\\nweighted avg       0.92      0.92      0.92       120\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(y_test,y_pred3)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc901e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 7, 10, 25, 75, 50, 100],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;, &#x27;kd_tree&#x27;, &#x27;brute&#x27;],\n",
       "                         &#x27;n_neighbors&#x27;: [5, 7, 10, 25, 75, 50, 100],\n",
       "                         &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(), n_jobs=-1,\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
       "                         'n_neighbors': [5, 7, 10, 25, 75, 50, 100],\n",
       "                         'weights': ['uniform', 'distance']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "paraKNN={\"n_neighbors\":[5,7,10,25,75,50,100],\n",
    "        \"weights\":[\"uniform\", \"distance\"],\n",
    "        \"algorithm\":[\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "        }\n",
    "gridKNN=GridSearchCV(KNeighborsClassifier(),paraKNN,refit=True,verbose=3,n_jobs=-1)\n",
    "gridKNN.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b50b6c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.000427</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>auto</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 5, 'weigh...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.005695</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>auto</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 7, 'weigh...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000862</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.003225</td>\n",
       "      <td>auto</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 7, 'weigh...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.009023</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 10, 'weig...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.062474</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.003326</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>auto</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 10, 'weig...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.867857</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012026</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>auto</td>\n",
       "      <td>25</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 25, 'weig...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.066240</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.005996</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>auto</td>\n",
       "      <td>25</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 25, 'weig...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.003374</td>\n",
       "      <td>0.005767</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>auto</td>\n",
       "      <td>75</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 75, 'weig...</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.040721</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.006349</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>auto</td>\n",
       "      <td>75</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 75, 'weig...</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.782143</td>\n",
       "      <td>0.058029</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.009522</td>\n",
       "      <td>0.005450</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 50, 'weig...</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753571</td>\n",
       "      <td>0.052245</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>auto</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 50, 'weig...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.005596</td>\n",
       "      <td>0.006136</td>\n",
       "      <td>0.005853</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 100, 'wei...</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.029881</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>auto</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'auto', 'n_neighbors': 100, 'wei...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013142</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 5, '...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.005008</td>\n",
       "      <td>0.003158</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 5, '...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.005757</td>\n",
       "      <td>0.005964</td>\n",
       "      <td>0.004309</td>\n",
       "      <td>0.004051</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 7, '...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.001115</td>\n",
       "      <td>0.001451</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 7, '...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 10, ...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.062474</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 10, ...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.867857</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009668</td>\n",
       "      <td>0.008776</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>25</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 25, ...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.066240</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.003574</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>25</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 25, ...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.005543</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.007259</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>75</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 75, ...</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.040721</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>75</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 75, ...</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.782143</td>\n",
       "      <td>0.058029</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.001187</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 50, ...</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753571</td>\n",
       "      <td>0.052245</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 50, ...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.001348</td>\n",
       "      <td>0.001866</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.029881</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'ball_tree', 'n_neighbors': 100,...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>0.002960</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.004727</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.003192</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.004931</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.062474</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000976</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.867857</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005130</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>25</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 25, 'w...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.066240</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.003605</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>25</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 25, 'w...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.010933</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>75</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 75, 'w...</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.040721</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>75</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 75, 'w...</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.782143</td>\n",
       "      <td>0.058029</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000826</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.010668</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753571</td>\n",
       "      <td>0.052245</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.000903</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.002668</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 100, '...</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.029881</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.006622</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'kd_tree', 'n_neighbors': 100, '...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.099088</td>\n",
       "      <td>0.040447</td>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 5, 'weig...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.096393</td>\n",
       "      <td>0.040133</td>\n",
       "      <td>brute</td>\n",
       "      <td>5</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 5, 'weig...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>0.039938</td>\n",
       "      <td>brute</td>\n",
       "      <td>7</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 7, 'weig...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.078234</td>\n",
       "      <td>0.001791</td>\n",
       "      <td>brute</td>\n",
       "      <td>7</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 7, 'weig...</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.882143</td>\n",
       "      <td>0.014286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.098602</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>brute</td>\n",
       "      <td>10</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 10, 'wei...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.062474</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.002362</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.077639</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>brute</td>\n",
       "      <td>10</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 10, 'wei...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.867857</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.002504</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.158839</td>\n",
       "      <td>0.044561</td>\n",
       "      <td>brute</td>\n",
       "      <td>25</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 25, 'wei...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.066240</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000883</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.077396</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>brute</td>\n",
       "      <td>25</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 25, 'wei...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.846429</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.079186</td>\n",
       "      <td>0.008184</td>\n",
       "      <td>brute</td>\n",
       "      <td>75</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 75, 'wei...</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.040721</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.074686</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>brute</td>\n",
       "      <td>75</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 75, 'wei...</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.782143</td>\n",
       "      <td>0.058029</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.003116</td>\n",
       "      <td>0.078446</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 50, 'wei...</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.660714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.753571</td>\n",
       "      <td>0.052245</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.001647</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.077715</td>\n",
       "      <td>0.005351</td>\n",
       "      <td>brute</td>\n",
       "      <td>50</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 50, 'wei...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.043154</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.002399</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.079714</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>brute</td>\n",
       "      <td>100</td>\n",
       "      <td>uniform</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 100, 'we...</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.029881</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.001610</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>0.065878</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>brute</td>\n",
       "      <td>100</td>\n",
       "      <td>distance</td>\n",
       "      <td>{'algorithm': 'brute', 'n_neighbors': 100, 'we...</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.033120</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.001836      0.000427         0.007303        0.002783   \n",
       "1        0.002101      0.002230         0.001341        0.001224   \n",
       "2        0.001331      0.000380         0.005695        0.003022   \n",
       "3        0.000639      0.000862         0.002586        0.003225   \n",
       "4        0.001220      0.000996         0.009023        0.007796   \n",
       "5        0.001554      0.001773         0.003326        0.006165   \n",
       "6        0.000000      0.000000         0.012026        0.009847   \n",
       "7        0.003735      0.005996         0.000746        0.001492   \n",
       "8        0.003374      0.005767         0.002725        0.003352   \n",
       "9        0.006349      0.006999         0.001941        0.001586   \n",
       "10       0.003599      0.005692         0.009522        0.005450   \n",
       "11       0.000399      0.000489         0.000199        0.000399   \n",
       "12       0.005596      0.006136         0.005853        0.004664   \n",
       "13       0.002771      0.005058         0.000550        0.001100   \n",
       "14       0.000000      0.000000         0.013142        0.002032   \n",
       "15       0.002946      0.005008         0.003158        0.003797   \n",
       "16       0.005757      0.005964         0.004309        0.004051   \n",
       "17       0.001081      0.001040         0.001115        0.001451   \n",
       "18       0.000201      0.000402         0.009919        0.008185   \n",
       "19       0.000396      0.000485         0.003206        0.006413   \n",
       "20       0.000000      0.000000         0.009668        0.008776   \n",
       "21       0.003846      0.006055         0.002545        0.003574   \n",
       "22       0.005543      0.006046         0.009507        0.007259   \n",
       "23       0.000742      0.000920         0.003505        0.006108   \n",
       "24       0.001187      0.001140         0.009422        0.006596   \n",
       "25       0.003190      0.006381         0.001465        0.002082   \n",
       "26       0.001348      0.001866         0.009279        0.005633   \n",
       "27       0.001182      0.001147         0.005202        0.005867   \n",
       "28       0.000000      0.000000         0.013489        0.002960   \n",
       "29       0.004727      0.004239         0.001334        0.001283   \n",
       "30       0.003192      0.003654         0.006828        0.005583   \n",
       "31       0.001465      0.001984         0.003720        0.006201   \n",
       "32       0.004178      0.006446         0.004931        0.004169   \n",
       "33       0.001201      0.000976         0.004717        0.002041   \n",
       "34       0.007275      0.005130         0.004652        0.003516   \n",
       "35       0.003605      0.003141         0.000798        0.001162   \n",
       "36       0.002427      0.002068         0.010933        0.004466   \n",
       "37       0.000810      0.000992         0.004168        0.002320   \n",
       "38       0.000826      0.000722         0.010668        0.003486   \n",
       "39       0.003081      0.000903         0.002780        0.002251   \n",
       "40       0.002668      0.002777         0.010204        0.001612   \n",
       "41       0.002062      0.002203         0.006622        0.003505   \n",
       "42       0.000999      0.001549         0.099088        0.040447   \n",
       "43       0.000932      0.000842         0.096393        0.040133   \n",
       "44       0.002013      0.003056         0.095000        0.039938   \n",
       "45       0.000722      0.000895         0.078234        0.001791   \n",
       "46       0.000507      0.000641         0.098602        0.041520   \n",
       "47       0.002362      0.002963         0.077639        0.002619   \n",
       "48       0.002504      0.002808         0.158839        0.044561   \n",
       "49       0.000883      0.000449         0.077396        0.004736   \n",
       "50       0.000257      0.000326         0.079186        0.008184   \n",
       "51       0.000969      0.000864         0.074686        0.003219   \n",
       "52       0.002015      0.003116         0.078446        0.002493   \n",
       "53       0.001647      0.001728         0.077715        0.005351   \n",
       "54       0.002399      0.001790         0.079714        0.003491   \n",
       "55       0.001610      0.002749         0.065878        0.011455   \n",
       "\n",
       "   param_algorithm param_n_neighbors param_weights  \\\n",
       "0             auto                 5       uniform   \n",
       "1             auto                 5      distance   \n",
       "2             auto                 7       uniform   \n",
       "3             auto                 7      distance   \n",
       "4             auto                10       uniform   \n",
       "5             auto                10      distance   \n",
       "6             auto                25       uniform   \n",
       "7             auto                25      distance   \n",
       "8             auto                75       uniform   \n",
       "9             auto                75      distance   \n",
       "10            auto                50       uniform   \n",
       "11            auto                50      distance   \n",
       "12            auto               100       uniform   \n",
       "13            auto               100      distance   \n",
       "14       ball_tree                 5       uniform   \n",
       "15       ball_tree                 5      distance   \n",
       "16       ball_tree                 7       uniform   \n",
       "17       ball_tree                 7      distance   \n",
       "18       ball_tree                10       uniform   \n",
       "19       ball_tree                10      distance   \n",
       "20       ball_tree                25       uniform   \n",
       "21       ball_tree                25      distance   \n",
       "22       ball_tree                75       uniform   \n",
       "23       ball_tree                75      distance   \n",
       "24       ball_tree                50       uniform   \n",
       "25       ball_tree                50      distance   \n",
       "26       ball_tree               100       uniform   \n",
       "27       ball_tree               100      distance   \n",
       "28         kd_tree                 5       uniform   \n",
       "29         kd_tree                 5      distance   \n",
       "30         kd_tree                 7       uniform   \n",
       "31         kd_tree                 7      distance   \n",
       "32         kd_tree                10       uniform   \n",
       "33         kd_tree                10      distance   \n",
       "34         kd_tree                25       uniform   \n",
       "35         kd_tree                25      distance   \n",
       "36         kd_tree                75       uniform   \n",
       "37         kd_tree                75      distance   \n",
       "38         kd_tree                50       uniform   \n",
       "39         kd_tree                50      distance   \n",
       "40         kd_tree               100       uniform   \n",
       "41         kd_tree               100      distance   \n",
       "42           brute                 5       uniform   \n",
       "43           brute                 5      distance   \n",
       "44           brute                 7       uniform   \n",
       "45           brute                 7      distance   \n",
       "46           brute                10       uniform   \n",
       "47           brute                10      distance   \n",
       "48           brute                25       uniform   \n",
       "49           brute                25      distance   \n",
       "50           brute                75       uniform   \n",
       "51           brute                75      distance   \n",
       "52           brute                50       uniform   \n",
       "53           brute                50      distance   \n",
       "54           brute               100       uniform   \n",
       "55           brute               100      distance   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'algorithm': 'auto', 'n_neighbors': 5, 'weigh...           0.875000   \n",
       "1   {'algorithm': 'auto', 'n_neighbors': 5, 'weigh...           0.875000   \n",
       "2   {'algorithm': 'auto', 'n_neighbors': 7, 'weigh...           0.875000   \n",
       "3   {'algorithm': 'auto', 'n_neighbors': 7, 'weigh...           0.875000   \n",
       "4   {'algorithm': 'auto', 'n_neighbors': 10, 'weig...           0.839286   \n",
       "5   {'algorithm': 'auto', 'n_neighbors': 10, 'weig...           0.857143   \n",
       "6   {'algorithm': 'auto', 'n_neighbors': 25, 'weig...           0.839286   \n",
       "7   {'algorithm': 'auto', 'n_neighbors': 25, 'weig...           0.857143   \n",
       "8   {'algorithm': 'auto', 'n_neighbors': 75, 'weig...           0.767857   \n",
       "9   {'algorithm': 'auto', 'n_neighbors': 75, 'weig...           0.803571   \n",
       "10  {'algorithm': 'auto', 'n_neighbors': 50, 'weig...           0.767857   \n",
       "11  {'algorithm': 'auto', 'n_neighbors': 50, 'weig...           0.839286   \n",
       "12  {'algorithm': 'auto', 'n_neighbors': 100, 'wei...           0.696429   \n",
       "13  {'algorithm': 'auto', 'n_neighbors': 100, 'wei...           0.750000   \n",
       "14  {'algorithm': 'ball_tree', 'n_neighbors': 5, '...           0.875000   \n",
       "15  {'algorithm': 'ball_tree', 'n_neighbors': 5, '...           0.875000   \n",
       "16  {'algorithm': 'ball_tree', 'n_neighbors': 7, '...           0.875000   \n",
       "17  {'algorithm': 'ball_tree', 'n_neighbors': 7, '...           0.875000   \n",
       "18  {'algorithm': 'ball_tree', 'n_neighbors': 10, ...           0.839286   \n",
       "19  {'algorithm': 'ball_tree', 'n_neighbors': 10, ...           0.857143   \n",
       "20  {'algorithm': 'ball_tree', 'n_neighbors': 25, ...           0.839286   \n",
       "21  {'algorithm': 'ball_tree', 'n_neighbors': 25, ...           0.857143   \n",
       "22  {'algorithm': 'ball_tree', 'n_neighbors': 75, ...           0.767857   \n",
       "23  {'algorithm': 'ball_tree', 'n_neighbors': 75, ...           0.803571   \n",
       "24  {'algorithm': 'ball_tree', 'n_neighbors': 50, ...           0.767857   \n",
       "25  {'algorithm': 'ball_tree', 'n_neighbors': 50, ...           0.839286   \n",
       "26  {'algorithm': 'ball_tree', 'n_neighbors': 100,...           0.696429   \n",
       "27  {'algorithm': 'ball_tree', 'n_neighbors': 100,...           0.750000   \n",
       "28  {'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...           0.875000   \n",
       "29  {'algorithm': 'kd_tree', 'n_neighbors': 5, 'we...           0.875000   \n",
       "30  {'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...           0.875000   \n",
       "31  {'algorithm': 'kd_tree', 'n_neighbors': 7, 'we...           0.875000   \n",
       "32  {'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...           0.839286   \n",
       "33  {'algorithm': 'kd_tree', 'n_neighbors': 10, 'w...           0.857143   \n",
       "34  {'algorithm': 'kd_tree', 'n_neighbors': 25, 'w...           0.839286   \n",
       "35  {'algorithm': 'kd_tree', 'n_neighbors': 25, 'w...           0.857143   \n",
       "36  {'algorithm': 'kd_tree', 'n_neighbors': 75, 'w...           0.767857   \n",
       "37  {'algorithm': 'kd_tree', 'n_neighbors': 75, 'w...           0.803571   \n",
       "38  {'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...           0.767857   \n",
       "39  {'algorithm': 'kd_tree', 'n_neighbors': 50, 'w...           0.839286   \n",
       "40  {'algorithm': 'kd_tree', 'n_neighbors': 100, '...           0.696429   \n",
       "41  {'algorithm': 'kd_tree', 'n_neighbors': 100, '...           0.750000   \n",
       "42  {'algorithm': 'brute', 'n_neighbors': 5, 'weig...           0.875000   \n",
       "43  {'algorithm': 'brute', 'n_neighbors': 5, 'weig...           0.875000   \n",
       "44  {'algorithm': 'brute', 'n_neighbors': 7, 'weig...           0.875000   \n",
       "45  {'algorithm': 'brute', 'n_neighbors': 7, 'weig...           0.875000   \n",
       "46  {'algorithm': 'brute', 'n_neighbors': 10, 'wei...           0.839286   \n",
       "47  {'algorithm': 'brute', 'n_neighbors': 10, 'wei...           0.857143   \n",
       "48  {'algorithm': 'brute', 'n_neighbors': 25, 'wei...           0.839286   \n",
       "49  {'algorithm': 'brute', 'n_neighbors': 25, 'wei...           0.857143   \n",
       "50  {'algorithm': 'brute', 'n_neighbors': 75, 'wei...           0.767857   \n",
       "51  {'algorithm': 'brute', 'n_neighbors': 75, 'wei...           0.803571   \n",
       "52  {'algorithm': 'brute', 'n_neighbors': 50, 'wei...           0.767857   \n",
       "53  {'algorithm': 'brute', 'n_neighbors': 50, 'wei...           0.839286   \n",
       "54  {'algorithm': 'brute', 'n_neighbors': 100, 'we...           0.696429   \n",
       "55  {'algorithm': 'brute', 'n_neighbors': 100, 'we...           0.750000   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.857143           0.857143           0.910714   \n",
       "1            0.857143           0.839286           0.892857   \n",
       "2            0.875000           0.839286           0.892857   \n",
       "3            0.875000           0.875000           0.910714   \n",
       "4            0.821429           0.714286           0.892857   \n",
       "5            0.875000           0.821429           0.892857   \n",
       "6            0.803571           0.678571           0.875000   \n",
       "7            0.839286           0.785714           0.875000   \n",
       "8            0.714286           0.660714           0.750000   \n",
       "9            0.785714           0.678571           0.857143   \n",
       "10           0.767857           0.660714           0.821429   \n",
       "11           0.821429           0.732143           0.857143   \n",
       "12           0.714286           0.642857           0.696429   \n",
       "13           0.750000           0.678571           0.767857   \n",
       "14           0.857143           0.857143           0.910714   \n",
       "15           0.857143           0.839286           0.892857   \n",
       "16           0.875000           0.839286           0.892857   \n",
       "17           0.875000           0.875000           0.910714   \n",
       "18           0.821429           0.714286           0.892857   \n",
       "19           0.875000           0.821429           0.892857   \n",
       "20           0.803571           0.678571           0.875000   \n",
       "21           0.839286           0.785714           0.875000   \n",
       "22           0.714286           0.660714           0.750000   \n",
       "23           0.785714           0.678571           0.857143   \n",
       "24           0.767857           0.660714           0.821429   \n",
       "25           0.821429           0.732143           0.857143   \n",
       "26           0.714286           0.642857           0.696429   \n",
       "27           0.750000           0.678571           0.767857   \n",
       "28           0.857143           0.857143           0.910714   \n",
       "29           0.857143           0.839286           0.892857   \n",
       "30           0.875000           0.839286           0.892857   \n",
       "31           0.875000           0.875000           0.910714   \n",
       "32           0.821429           0.714286           0.892857   \n",
       "33           0.875000           0.821429           0.892857   \n",
       "34           0.803571           0.678571           0.875000   \n",
       "35           0.839286           0.785714           0.875000   \n",
       "36           0.714286           0.660714           0.750000   \n",
       "37           0.785714           0.678571           0.857143   \n",
       "38           0.767857           0.660714           0.821429   \n",
       "39           0.821429           0.732143           0.857143   \n",
       "40           0.714286           0.642857           0.696429   \n",
       "41           0.750000           0.678571           0.767857   \n",
       "42           0.857143           0.857143           0.910714   \n",
       "43           0.857143           0.839286           0.892857   \n",
       "44           0.875000           0.839286           0.892857   \n",
       "45           0.875000           0.875000           0.910714   \n",
       "46           0.821429           0.714286           0.892857   \n",
       "47           0.875000           0.821429           0.892857   \n",
       "48           0.803571           0.678571           0.875000   \n",
       "49           0.839286           0.785714           0.875000   \n",
       "50           0.714286           0.660714           0.750000   \n",
       "51           0.785714           0.678571           0.857143   \n",
       "52           0.767857           0.660714           0.821429   \n",
       "53           0.821429           0.732143           0.857143   \n",
       "54           0.714286           0.642857           0.696429   \n",
       "55           0.750000           0.678571           0.767857   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.892857         0.878571        0.020825                5  \n",
       "1            0.892857         0.871429        0.020825                9  \n",
       "2            0.875000         0.871429        0.017496                9  \n",
       "3            0.875000         0.882143        0.014286                1  \n",
       "4            0.875000         0.828571        0.062474               25  \n",
       "5            0.892857         0.867857        0.026726               17  \n",
       "6            0.803571         0.800000        0.066240               33  \n",
       "7            0.875000         0.846429        0.033120               21  \n",
       "8            0.678571         0.714286        0.040721               49  \n",
       "9            0.785714         0.782143        0.058029               37  \n",
       "10           0.750000         0.753571        0.052245               41  \n",
       "11           0.821429         0.814286        0.043154               29  \n",
       "12           0.642857         0.678571        0.029881               53  \n",
       "13           0.767857         0.742857        0.033120               45  \n",
       "14           0.892857         0.878571        0.020825                5  \n",
       "15           0.892857         0.871429        0.020825                9  \n",
       "16           0.875000         0.871429        0.017496                9  \n",
       "17           0.875000         0.882143        0.014286                1  \n",
       "18           0.875000         0.828571        0.062474               25  \n",
       "19           0.892857         0.867857        0.026726               17  \n",
       "20           0.803571         0.800000        0.066240               33  \n",
       "21           0.875000         0.846429        0.033120               21  \n",
       "22           0.678571         0.714286        0.040721               49  \n",
       "23           0.785714         0.782143        0.058029               37  \n",
       "24           0.750000         0.753571        0.052245               41  \n",
       "25           0.821429         0.814286        0.043154               29  \n",
       "26           0.642857         0.678571        0.029881               53  \n",
       "27           0.767857         0.742857        0.033120               45  \n",
       "28           0.892857         0.878571        0.020825                5  \n",
       "29           0.892857         0.871429        0.020825                9  \n",
       "30           0.875000         0.871429        0.017496                9  \n",
       "31           0.875000         0.882143        0.014286                1  \n",
       "32           0.875000         0.828571        0.062474               25  \n",
       "33           0.892857         0.867857        0.026726               17  \n",
       "34           0.803571         0.800000        0.066240               33  \n",
       "35           0.875000         0.846429        0.033120               21  \n",
       "36           0.678571         0.714286        0.040721               49  \n",
       "37           0.785714         0.782143        0.058029               37  \n",
       "38           0.750000         0.753571        0.052245               41  \n",
       "39           0.821429         0.814286        0.043154               29  \n",
       "40           0.642857         0.678571        0.029881               53  \n",
       "41           0.767857         0.742857        0.033120               45  \n",
       "42           0.892857         0.878571        0.020825                5  \n",
       "43           0.892857         0.871429        0.020825                9  \n",
       "44           0.875000         0.871429        0.017496                9  \n",
       "45           0.875000         0.882143        0.014286                1  \n",
       "46           0.875000         0.828571        0.062474               25  \n",
       "47           0.892857         0.867857        0.026726               17  \n",
       "48           0.803571         0.800000        0.066240               33  \n",
       "49           0.875000         0.846429        0.033120               21  \n",
       "50           0.678571         0.714286        0.040721               49  \n",
       "51           0.785714         0.782143        0.058029               37  \n",
       "52           0.750000         0.753571        0.052245               41  \n",
       "53           0.821429         0.814286        0.043154               29  \n",
       "54           0.642857         0.678571        0.029881               53  \n",
       "55           0.767857         0.742857        0.033120               45  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred4=gridKNN.predict(X_test)\n",
    "re4=gridKNN.cv_results_\n",
    "data4=pd.DataFrame.from_dict(re4)\n",
    "data4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cec2227e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75,  4],\n",
       "       [ 6, 35]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi=confusion_matrix(y_test,y_pred4)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa5f3a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.93      0.95      0.94        79\\n           1       0.90      0.85      0.88        41\\n\\n    accuracy                           0.92       120\\n   macro avg       0.91      0.90      0.91       120\\nweighted avg       0.92      0.92      0.92       120\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(y_test,y_pred4)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "379bb6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaussNB=GaussianNB()\n",
    "gaussNB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34523a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred5=gaussNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e274c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75,  4],\n",
       "       [ 8, 33]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi=confusion_matrix(y_test,y_pred5)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ba37a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.90      0.95      0.93        79\\n           1       0.89      0.80      0.85        41\\n\\n    accuracy                           0.90       120\\n   macro avg       0.90      0.88      0.89       120\\nweighted avg       0.90      0.90      0.90       120\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(y_test,y_pred5)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8b87fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "berNB= BernoulliNB()\n",
    "berNB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "09370d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred6=berNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb344583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73,  6],\n",
       "       [22, 19]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi=confusion_matrix(y_test,y_pred6)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22167fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.77      0.92      0.84        79\\n           1       0.76      0.46      0.58        41\\n\\n    accuracy                           0.77       120\\n   macro avg       0.76      0.69      0.71       120\\nweighted avg       0.77      0.77      0.75       120\\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(y_test,y_pred6)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8cac810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "comNB= ComplementNB()\n",
    "comNB.fit(m_train,y_train)\n",
    "y_pred7=berNB.predict(m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bc0edc7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 75],\n",
       "       [ 0, 41]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi=confusion_matrix(y_test,y_pred7)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08e6f231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      0.05      0.10        79\\n           1       0.35      1.00      0.52        41\\n\\n    accuracy                           0.38       120\\n   macro avg       0.68      0.53      0.31       120\\nweighted avg       0.78      0.38      0.24       120\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(y_test,y_pred7)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "75f153fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import CategoricalNB\n",
    "catNB= CategoricalNB()\n",
    "catNB.fit(m_train,y_train)\n",
    "y_pred8=berNB.predict(m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60742ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 75],\n",
       "       [ 0, 41]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi=confusion_matrix(y_test,y_pred8)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab7c37b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      0.05      0.10        79\\n           1       0.35      1.00      0.52        41\\n\\n    accuracy                           0.38       120\\n   macro avg       0.68      0.53      0.31       120\\nweighted avg       0.78      0.38      0.24       120\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(y_test,y_pred8)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19bb449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mulNB=MultinomialNB()\n",
    "mulNB.fit(m_train,y_train)\n",
    "y_pred9=berNB.predict(m_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd2ab1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 75],\n",
       "       [ 0, 41]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classi=confusion_matrix(y_test,y_pred9)\n",
    "classi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2c0719c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       1.00      0.05      0.10        79\\n           1       0.35      1.00      0.52        41\\n\\n    accuracy                           0.38       120\\n   macro avg       0.68      0.53      0.31       120\\nweighted avg       0.78      0.38      0.24       120\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report=classification_report(y_test,y_pred9)\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29f055df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5d74562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"Finalaized_Model.sav\"\n",
    "pickle.dump(gridKNN,open(filename,\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ba011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdde4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
